{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Tq5NBOozKC0B"},"outputs":[],"source":["%cd /content/drive/MyDrive/\n","# %mkdir cc\n","%cd img_align_celeba/img_align_celeba\n","%pwd\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"fr_l39jW5HMy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JjASGCAxZQBX"},"outputs":[],"source":["import torch.nn as nn\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBENGN15aV6_"},"outputs":[],"source":["from __future__ import print_function\n","\n","import argparse\n","import os\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","\n","manualSeed = 999\n","print(\"Random Seed: \", manualSeed)\n","random.seed(manualSeed)\n","torch.manual_seed(manualSeed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWC3mc4JaW49"},"outputs":[],"source":["\n","dataroot = \"/content/drive/MyDrive/cc/img_align_celeba\"\n","\n","\n","workers = 2\n","\n","\n","batch_size = 128\n","\n","\n","image_size = 64\n","\n","\n","nc = 3\n","\n","\n","nz = 100\n","\n","\n","ngf = 64\n","\n","\n","ndf = 64\n","\n","num_epochs = 15\n","\n","\n","lr = 0.0002\n","\n","\n","beta1 = 0.5\n","\n","\n","ngpu = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kx5Npq7uabmQ"},"outputs":[],"source":["\n","dataset = dset.ImageFolder(root=dataroot,\n","                           transform=transforms.Compose([\n","                               transforms.Resize(image_size),\n","                               transforms.CenterCrop(image_size),\n","                               transforms.ToTensor(),\n","                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                           ]))\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n","                                         shuffle=True, num_workers=workers)\n","\n","\n","device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","\n","\n","real_batch = next(iter(dataloader))\n","plt.figure(figsize=(8,8))\n","plt.axis(\"off\")\n","plt.title(\"Training Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BvwP-RYaeHai"},"outputs":[],"source":["print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"INz2_6u1b-Be"},"outputs":[],"source":["\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2hYlgLrcBiJ"},"outputs":[],"source":["\n","\n","class Generator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Generator, self).__init__()\n","        self.ngpu = ngpu\n","        self.nz = nz\n","        self.ngf = ngf\n","        self.nc = nc\n","\n","        self.main = nn.Sequential(\n","            \n","            nn.Linear(nz, ngf  * 4 * 4),\n","            nn.BatchNorm1d(ngf  * 4 * 4),\n","            nn.ReLU(True),\n","            \n","            nn.Linear(ngf  * 4 * 4, ngf  * 8 * 8),\n","            nn.BatchNorm1d(ngf  * 8 * 8),\n","            nn.ReLU(True),\n","            \n","            nn.Linear(ngf  * 8 * 8, nc * 64 * 64),\n","            nn.Tanh()\n","           \n","        )\n","\n","    def forward(self, input):\n","        \n","        input = input.view(input.size(0), self.nz)\n","        output = self.main(input)\n","        return output.view(input.size(0), self.nc, 64, 64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYLvZvlpeXoP"},"outputs":[],"source":["\n","netG = Generator(ngpu).to(device)\n","\n","\n","if (device.type == 'cuda') and (ngpu > 1):\n","    netG = nn.DataParallel(netG, list(range(ngpu)))\n","\n","\n","netG.apply(weights_init)\n","\n","print(netG)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GKZ3_o8Iea3g"},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Discriminator, self).__init__()\n","        self.ngpu = ngpu\n","        self.nc = nc\n","        self.ndf = ndf\n","\n","        self.main = nn.Sequential(\n","           \n","            nn.Linear(nc * 64 * 64, ndf * 4 * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            \n","            nn.Linear(ndf * 4 * 4, ndf * 2 * 4 * 4),\n","            nn.BatchNorm1d(ndf * 2 * 4 * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            \n","            nn.Linear(ndf * 2 * 4 * 4, ndf * 4 * 4 * 4),\n","            nn.BatchNorm1d(ndf * 4 * 4 * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            \n","            nn.Linear(ndf * 4 * 4 * 4, ndf * 8 * 4 * 4),\n","            nn.BatchNorm1d(ndf * 8 * 4 * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            \n","            nn.Linear(ndf * 8 * 4 * 4, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        input = input.view(input.size(0), -1)\n","        return self.main(input)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sanXEuW3eblv"},"outputs":[],"source":["\n","netD = Discriminator(ngpu).to(device)\n","\n","\n","if (device.type == 'cuda') and (ngpu > 1):\n","    netD = nn.DataParallel(netD, list(range(ngpu)))\n","\n","\n","netD.apply(weights_init)\n","print(netD)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tCEQnkWPeecK"},"outputs":[],"source":["\n","criterion = nn.BCELoss()\n","\n","\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","\n","real_label = 1.\n","fake_label = 0.\n","\n","\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dChMuQXIeefG"},"outputs":[],"source":["\n","img_list = []\n","G_losses = []\n","D_losses = []\n","ff=[]\n","iters = 0\n","\n","print(\"Starting Training Loop...\")\n","\n","for epoch in range(num_epochs):\n","  \n","    for i, data in enumerate(dataloader, 0):\n","\n","        \n","        netD.zero_grad()\n","        \n","        real_cpu = data[0].to(device)\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","     \n","        output = netD(real_cpu).view(-1)\n","       \n","        errD_real = criterion(output, label)\n","       \n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        \n","        noise = torch.randn(b_size, nz, 1, 1, device=device)\n","     \n","        fake = netG(noise)\n","        label.fill_(fake_label)\n","   \n","        output = netD(fake.detach()).view(-1)\n","        \n","        errD_fake = criterion(output, label)\n","        \n","        errD_fake.backward()\n","        D_G_z1 = output.mean().item()\n","\n","        errD = errD_real + errD_fake\n","        \n","        optimizerD.step()\n","\n","        \n","        netG.zero_grad()\n","        label.fill_(real_label)  \n","  \n","        output = netD(fake).view(-1)\n","        \n","        errG = criterion(output, label)\n","        \n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","        \n","        optimizerG.step()\n","\n","        \n","        if i % 50 == 0:\n","            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","                  % (epoch, num_epochs, i, len(dataloader),\n","                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        \n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","\n","        \n","        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n","            with torch.no_grad():\n","                fake = netG(fixed_noise).detach().cpu()\n","                ff.append(fake)\n","            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","        iters += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9Pp7jQeepKJ"},"outputs":[],"source":["plt.figure(figsize=(10,5))\n","plt.title(\"Generator and Discriminator Loss During Training\")\n","plt.plot(G_losses,label=\"G\")\n","plt.plot(D_losses,label=\"D\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A5U5JwShep2n"},"outputs":[],"source":["fig = plt.figure(figsize=(8,8))\n","plt.axis(\"off\")\n","ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n","ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n","\n","HTML(ani.to_jshtml())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvpCZPKQevex"},"outputs":[],"source":["\n","real_batch = next(iter(dataloader))\n","\n","\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,2,1)\n","plt.axis(\"off\")\n","plt.title(\"Real Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n","\n","\n","plt.subplot(1,2,2)\n","plt.axis(\"off\")\n","plt.title(\"Fake Images\")\n","plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n","plt.show()"]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import numpy as np\n","\n","save_folder_path = '/content/drive/MyDrive/c/'\n","\n","\n","os.makedirs(save_folder_path, exist_ok=True)\n","\n","\n","for index, img in enumerate(ff):\n","    file_name = f'image_{index}.png'  \n","    file_path = os.path.join(save_folder_path, file_name)\n","    \n","\n","    np_img = img.detach().cpu().numpy()  \n","    np_img = np.transpose(np_img, (1, 2, 0))  \n","    Image.fromarray((np_img * 255).astype(np.uint8)).save(file_path)  \n"],"metadata":{"id":"kh4xQVa1AmMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import numpy as np\n","\n","save_folder_path = '/content/drive/MyDrive/c/'\n","\n","\n","os.makedirs(save_folder_path, exist_ok=True)\n","\n","\n","for batch_index, img_batch in enumerate(ff):\n","    for img_index, img in enumerate(img_batch):\n","        file_name = f'image_{batch_index}_{img_index}.png'  \n","        file_path = os.path.join(save_folder_path, file_name)\n","\n","  \n","        np_img = img.detach().cpu().numpy()  \n","        np_img = np.transpose(np_img, (1, 2, 0)) \n","        np_img = (np_img * 255).astype(np.uint8)  \n","        Image.fromarray(np_img).save(file_path)\n"],"metadata":{"id":"wR9uJDMDS2Gd"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}